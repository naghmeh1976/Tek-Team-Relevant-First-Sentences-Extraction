{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naghmeh1976/Tek-Team-Relevant-First-Sentences-Extraction/blob/main/Relevant%26FirstSentences_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaMkAq5Bbd7J",
        "outputId": "efbcc169-82c9-4888-9ef6-1654dc9bf3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.37.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDvURBY3izCn",
        "outputId": "588a6fe5-b62e-4ac3-c640-0ff343275edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "jdZ8xSH4bfRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86865474-814d-41b8-df66-d44b8891702f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant_sentences(url):\n",
        "    # Fetch webpage content\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    # Extract text from the webpage\n",
        "    paragraphs = soup.find_all('p')\n",
        "    article_text = ' '.join([paragraph.text for paragraph in paragraphs])\n",
        "\n",
        "    # Tokenize article into sentences\n",
        "    sentences = sent_tokenize(article_text)\n",
        "\n",
        "    # Load SentenceTransformer model\n",
        "    model = SentenceTransformer(\"BAAI/bge-m3\")\n",
        "\n",
        "    # Encode sentences\n",
        "    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "    # Compute similarity scores between sentences and the first sentence\n",
        "    query_embedding = sentence_embeddings[0]\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, sentence_embeddings)[0]\n",
        "\n",
        "    # Define similarity threshold\n",
        "    similarity_threshold = 0.60  # Adjust as needed\n",
        "\n",
        "    # Select all sentences above the similarity threshold\n",
        "    relevant_sentences = [sentence for sentence, score in zip(sentences, similarities) if score.item() > similarity_threshold]\n",
        "\n",
        "    relevant_sentences_joined = '\\n'.join(relevant_sentences)\n",
        "\n",
        "    return relevant_sentences_joined\n"
      ],
      "metadata": {
        "id": "Qo5JImetdYDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_first_sentence(url):\n",
        "    # Send HTTP GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract the first paragraph and its text\n",
        "    first_paragraph = soup.find('p')\n",
        "    first_sentence = sent_tokenize(first_paragraph.text)[0]\n",
        "\n",
        "    return first_sentence"
      ],
      "metadata": {
        "id": "fLDtLM1Zl-RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_url=input(\"Enter URL to get the most relevant sentences\")\n",
        "relevant = get_relevant_sentences(input_url)\n",
        "first = extract_first_sentence(input_url)\n",
        "\n",
        "print(\"Relevant Sentences:\")\n",
        "print(relevant)\n",
        "print()\n",
        "print(\"\\nFirst sentence of the article:\")\n",
        "print(first)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdQTvNsKbhkh",
        "outputId": "605719ea-5902-4286-d971-5d55d498705b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter URL to get the most relevant sentenceshttps://www.theguardian.com/technology/2023/apr/27/elon-musks-statements-could-be-deepfakes-tesla-defence-lawyers-tell-court\n",
            "Relevant Sentences:\n",
            "Judge in Autopilot death case says defence argument ‘deeply troubling’ and wants Tesla CEO interviewed under oath on safety claims A California judge has tentatively ordered Elon Musk to be interviewed under oath about whether he made certain statements regarding the capabilities of Tesla’s Autopilot features after the company questioned the authenticity of the remarks, claiming Musk is a “target for deep fakes”.\n",
            "The attorneys for Huang’s family sought to depose Musk regarding recorded statements from 2016 in which he allegedly said: “A Model S and Model X, at this point, can drive autonomously with greater safety than a person.\n",
            "Right now.” Tesla, however, opposed the request in court filings, arguing that Musk, the Tesla CEO, cannot recall details about the statement and questioning the authenticity of the recording.\n",
            "“[Musk], like many public figures, is the subject of many ‘deepfake’ videos and audio recordings that purport to show him saying and doing things he never actually said or did,” Tesla said.\n",
            "Judge Evette Pennypacker tentatively ordered a limited, three-hour deposition where Musk could be asked whether he actually made the statements on the recordings, and called Tesla’s arguments “deeply troubling”.\n",
            "In June 2016 video of Musk speaking at a conference was uploaded to YouTube, and shows the Tesla CEO making the statement that the attorneys for Huang’s family refer to.\n",
            "The lawsuit is scheduled to go into trial on 31 July, adding to growing legal and regulatory scrutiny over Tesla’s Autopilot system.\n",
            "\n",
            "\n",
            "First sentence of the article:\n",
            "Judge in Autopilot death case says defence argument ‘deeply troubling’ and wants Tesla CEO interviewed under oath on safety claims\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vei92amAiYip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}